{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a59d9ad-6a4a-4156-8a20-89a7035c019e",
   "metadata": {},
   "source": [
    "### Finetuning on 900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15a58f6b-8784-4d9a-a88d-7b879e3b143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from improved_diffusion.script_util import create_model, create_gaussian_diffusion\n",
    "\n",
    "a = 1 # Temporary\n",
    "\n",
    "\n",
    "image_size=64\n",
    "num_channels=128\n",
    "num_res_blocks=3\n",
    "num_heads=4\n",
    "num_heads_upsample=-1\n",
    "attention_resolutions=\"16,8\"\n",
    "dropout=0.0\n",
    "learn_sigma=True\n",
    "sigma_small=False\n",
    "class_cond=False\n",
    "diffusion_steps=4000\n",
    "noise_schedule=\"cosine\"\n",
    "timestep_respacing=\"\"\n",
    "use_kl=False\n",
    "predict_xstart=False\n",
    "rescale_timesteps=True\n",
    "rescale_learned_sigmas=True\n",
    "use_checkpoint=False # To do gradient checkpointing\n",
    "use_scale_shift_norm=True\n",
    "\n",
    "clip_denoised=True\n",
    "num_samples=1000\n",
    "batch_size=16\n",
    "use_ddim=False\n",
    "\n",
    "# --------------Training related ------------\n",
    "\n",
    "schedule_sampler=\"uniform\" # For time-step, should it be uniform or changing based on loss function\n",
    "lr=1e-4\n",
    "weight_decay=0.0\n",
    "lr_anneal_steps=0\n",
    "microbatch=-1  # -1 disables microbatches\n",
    "ema_rate=\"0.9999\"  # comma-separated list of EMA values\n",
    "log_interval=10\n",
    "save_interval=10000 # Save checkpoints every X steps\n",
    "use_fp16=False\n",
    "fp16_scale_growth=1e-3\n",
    "\n",
    "# ------------- PATHS -------------------\n",
    "# Load pretrained model from here\n",
    "load_model_path=\"./results/pretrained_imagenet/checkpoints/imagenet64_uncond_100M_1500K.pt\"\n",
    "# The dataset you want to finetune on\n",
    "data_dir = './results/pokemon900/dataset/'\n",
    "# If you are resuming a previously aborted training, include the path to the checkpoint here\n",
    "resume_checkpoint=\"\" \n",
    "# Where to log the training loss (File does not have to exist)\n",
    "loss_logger=\"./results/pokemon900/finetuning/trainlog.csv\"\n",
    "# Directory to save checkpoints in\n",
    "checkpoint_dir = \"./results/pokemon900/finetuning/checkpoints/\"\n",
    "# Whenever you are saving checkpoints, a batch of images are also sampled, where to produce these images\n",
    "save_samples_dir= \"./results/pokemon900/finetuning/samples/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789bbfcf-da1f-4faa-abd6-4dc5f3cdccdc",
   "metadata": {},
   "source": [
    "### Create UNet and Diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b6806e5-b260-4ae0-bb3f-1b9121bbedd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import matplotlib.pyplot as plt \n",
    "import torch as th\n",
    "from improved_diffusion.script_util import create_model, create_gaussian_diffusion\n",
    "\n",
    "\n",
    "model = create_model(\n",
    "        image_size = image_size,\n",
    "        num_channels = num_channels,\n",
    "        num_res_blocks = num_res_blocks,\n",
    "        learn_sigma= learn_sigma,\n",
    "        class_cond= class_cond,\n",
    "        use_checkpoint= use_checkpoint,\n",
    "        attention_resolutions=attention_resolutions,\n",
    "        num_heads=num_heads,\n",
    "        num_heads_upsample=num_heads_upsample,\n",
    "        use_scale_shift_norm=use_scale_shift_norm,\n",
    "        dropout=dropout,\n",
    "        time_aware = time_aware # TIMEAWARE\n",
    ")\n",
    "\n",
    "\n",
    "diffusion = create_gaussian_diffusion(\n",
    "    steps=diffusion_steps,\n",
    "    learn_sigma=learn_sigma,\n",
    "    sigma_small=sigma_small,\n",
    "    noise_schedule=noise_schedule,\n",
    "    use_kl=use_kl,\n",
    "    predict_xstart=predict_xstart,\n",
    "    rescale_timesteps=rescale_timesteps,\n",
    "    rescale_learned_sigmas=rescale_learned_sigmas,\n",
    "    timestep_respacing=timestep_respacing,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6add9a5d-e67f-4319-bb45-e4239d34de75",
   "metadata": {},
   "source": [
    "### Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f8903cb-a08d-4a8c-9428-f2f1d64ad767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path=load_model_path\n",
    "checkpoint = th.load(model_path)\n",
    "model.load_state_dict(checkpoint, strict = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3f8a15-7970-4af5-9f60-6711f8585ae4",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c09b9936-18fe-4ca3-b2ef-6f449f533c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object load_data at 0x000001FE2943F4C0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from improved_diffusion.image_datasets import load_data\n",
    "from improved_diffusion.resample import create_named_schedule_sampler\n",
    "from improved_diffusion.train_util import TrainLoop\n",
    "\n",
    "data = load_data(\n",
    "    data_dir=data_dir,\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    class_cond=False,\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c6e0d7-ea16-4cea-af20-fbb80634d259",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3836a5-895c-40e2-99f6-a942b5680284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "sampling 16 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [2:26:39,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "sampling 16 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [4:53:19,  1.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "sampling 16 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30000it [7:20:00,  1.28it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "sampling 16 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40000it [9:46:45,  1.28it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "sampling 16 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [12:13:22,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "sampling 16 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60000it [14:40:46,  1.14it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "sampling 16 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70000it [17:09:28,  1.30it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "sampling 16 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80000it [19:36:33,  1.14it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "sampling 16 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87155it [21:26:45,  1.22it/s] "
     ]
    }
   ],
   "source": [
    "from improved_diffusion import dist_util\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "schedule_sampler = create_named_schedule_sampler(\"uniform\", diffusion)\n",
    "\n",
    "TrainLoop(\n",
    "    model=model,\n",
    "    diffusion=diffusion,\n",
    "    data=data,\n",
    "    batch_size=batch_size,\n",
    "    microbatch=microbatch,\n",
    "    lr=lr,\n",
    "    ema_rate=ema_rate,\n",
    "    log_interval=log_interval,\n",
    "    save_interval=save_interval,\n",
    "    resume_checkpoint=resume_checkpoint,\n",
    "    use_fp16=use_fp16,\n",
    "    fp16_scale_growth=fp16_scale_growth,\n",
    "    schedule_sampler=schedule_sampler,\n",
    "    weight_decay=weight_decay,\n",
    "    lr_anneal_steps=lr_anneal_steps,\n",
    "    # next 2 For logging\n",
    "    loss_logger=loss_logger,\n",
    "    checkpoint_dir = checkpoint_dir,\n",
    "    # next 4 For sampling\n",
    "    sample = True, # Doing sampling for a batch in training every time saving\n",
    "    use_ddim=use_ddim,\n",
    "    save_samples_dir=save_samples_dir,\n",
    "    image_size=image_size\n",
    ").run_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf08f70b-e9ba-4f96-b900-25f0b17c10ff",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2316014-bdc4-472c-be15-b3ea978af90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "clip_denoised=True\n",
    "num_samples=1000\n",
    "batch_size=20\n",
    "use_ddim=False \n",
    "save_samples_dir =\"./results/pokemon900/a3ft/samples/_25000/\" # Change these\n",
    "model_path = \"./results/pokemon900/a3ft/checkpoints/model250000.pt\" # Change these\n",
    "\n",
    "checkpoint = th.load(model_path)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "\n",
    "all_images = []\n",
    "all_labels = []\n",
    "i = 1\n",
    "while len(all_images) * batch_size < num_samples:\n",
    "\n",
    "    print(f\"sampling {batch_size} images\")\n",
    "    sample_fn = (diffusion.p_sample_loop if not use_ddim else self.diffusion.ddim_sample_loop)\n",
    "    sample = sample_fn(\n",
    "        model,\n",
    "        (batch_size, 3, image_size , image_size),\n",
    "        clip_denoised=True,\n",
    "        model_kwargs={}, # This is not needed, just class conditional stuff\n",
    "        progress=True\n",
    "    )\n",
    "    sample = ((sample + 1) * 127.5).clamp(0, 255).to(th.uint8)\n",
    "    sample = sample.permute(0, 2, 3, 1)\n",
    "    sample = sample.contiguous().cpu().numpy()\n",
    "\n",
    "    # Save images\n",
    "    for sidx, s in enumerate(sample):\n",
    "        plt.imsave(os.path.join(save_samples_dir, f'{sidx + i*b}.jpg'), s)\n",
    "\n",
    "    i = i+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
